# CS205 Final Project
# Janet Song and Will Sun
#
# Process abstracts for similarity analysis.
# 
# Bag-of-words and bigram representations, also stopword removal and tf-idf
# calculation

import re
import sys
from sys import argv
import csv
from collections import defaultdict
import numpy as np
import scipy as sp
import math
from mpi4py import MPI

from abstract import Abstract

# Serial load
def load(filename, abstracts, dictionary, stops):
    dictlist = []
            
    with open(filename) as csvfile:
        scrapedata = csv.reader(csvfile)
        for row in scrapedata:
            # check if duplicate
            if row[0] not in abstracts:
                abs, dictlist = load_abs(row, dictlist, stops)
                abstracts.append(abs)

    # create dictionary
    dictionary = create_dict(dictlist, dictionary)

# load abstract
def load_abs(row, dictlist, stops):
    abs = Abstract(row[0])
    abs.Set('title', row[1])
    abs.Set('text', row[2][10:])
    abs.Set('tags', row[3].split(','))
    
    # remove stop words and clean text
    abstext = [''.join([c.lower() for c in word if c.isalnum()]) for word in row[2][10:].split() if word not in stops]
    abs.Set('cleantext', abstext)
    
    for word in abstext:
        dictlist.append(word)
    
    return abs, dictlist
    
# Create dictionary
def create_dict(dictlist, dictionary):
    dictlist = [word for word in dictlist if dictlist.count(word) > 1]
    for word in dictlist:
        if word not in dictionary:
            dictionary.append(word)
    dictionary.sort()
    return dictionary

# Serial bag of words
def create_bagofwords(abstract, dictionary):
    bow = defaultdict(float)
    abstext = abstract.Get('cleantext')
    for word in abstext:
        if word in dictionary:
            ind = dictionary.index(word)
            bow[ind] += 1.0
    normalize(bow)
    return bow

# Serial bigrams
def create_bigram(abstract, dictionary):
    bigram = defaultdict(float)
    abstext = abstract.Get('cleantext')
    for i in range(len(abstext)-1):
        wordgram = abstext[i:i+2]
        wordgram.sort()
        if wordgram[0] in dictionary:
            if wordgram[1] in dictionary:
                pair = (dictionary.index(wordgram[0]),dictionary.index(wordgram[1]))
                bigram[pair] += 1.0
    normalize(bigram)
    return bigram

# Serial TFIDF for bag of words or bigrams
def serial_tfidf(abstracts, type):
    termdoc = termall(abstracts, type)
    numabs = float(len(abstracts))
    for abstract in abstracts:
        tfidf = create_tfidf(abstract, termdoc, numabs, type)
        abstract.Set('tfidf'+type, tfidf)

# Find TFIDF for type
def create_tfidf(abstract, termdoc, numabs, type):
    tfidf = defaultdict(float)
    for ind, freq in abstract.Get(type).iteritems():
        tfidf[ind] = freq*math.log(numabs/termdoc[ind])
    return tfidf

# Find number of documents in which a phrase or word appears
def termall(abstracts, type):
    termall = defaultdict(float)
    for abstract in abstracts:
        for ind, count in abstract.Get(type).iteritems():
            termall[ind] += 1.0
    return termall

# Serial normalize
def normalize(array):
    numwords = float(sum(array.values()))
    for ind, count in array.iteritems():
        array[ind] = count/numwords
    return array

# Master for MPI
def master(comm, filename):
    # initialize variables
    size = comm.Get_size()
    status = MPI.Status()
    abstracts = []
    dictlist = []
    dictionary = []
    termbow = []
    termbigram = []
    numabs = 0

    # load stop words
    stops = set()
    stop_file = 'stopwords.txt'
    with open(stop_file, 'rU') as stopFile:
        for row in stopFile.readlines():
            stops.add(row.replace('\n', ''))

    initial = 1
    # Load abstracts
    print "Loading abstracts ..."
    with open(filename) as csvfile:
        scrapedata = csv.reader(csvfile)
        for row in scrapedata:
            # check if duplicate
            if row[0] not in abstracts:
                # send first row to each slave
                # TODO: check if size > num of rows
                if initial < size:
                    comm.send((row,stops), dest=initial)
                    initial += 1
                else:
                    # continue sending rows to slaves
                    abs, dict = comm.recv(source=MPI.ANY_SOURCE, status=status)
                    abstracts.append(abs)
                    dictlist.extend(dict)
                    comm.send((row, stops), dest=status.Get_source())
                
        # tell slaves when there are no rows left
        for rank in range(1,size):
            abs, dict = comm.recv(source=MPI.ANY_SOURCE, status=status)
            abstracts.append(abs)
            dictlist.extend(dict)
            comm.send((None, None), dest=status.Get_source())
    print abstracts
    
    # Create dictionary
    print "Creating dictionary ..."
    dictionary = create_dict(dictlist, dictionary)
    print dictionary
    
    # Bag of words and Bigrams
    print "Creating bag of words and bigrams ..."
    ind = 0
    for abstract in abstracts:
        # send first abstract to each slave
        if ind < size-1:
            comm.send((abstract, dictionary), dest=ind+1, tag=ind)
            ind += 1
        # continue sending rows to slaves
        else:
            bow, bigram = comm.recv(source=MPI.ANY_SOURCE, tag=MPI.ANY_TAG, status=status)
            abstracts[status.Get_tag()].Set('bow', bow)
            abstracts[status.Get_tag()].Set('bigram', bigram)
            comm.send((abstract, dictionary), dest=status.Get_source(), tag=ind)  
            ind += 1
    
    # tell slaves when there are no abstracts left
    for rank in range(1,size):
        bow, bigram = comm.recv(source=MPI.ANY_SOURCE, tag=MPI.ANY_TAG, status=status)
        abstracts[status.Get_tag()].Set('bow', bow)
        abstracts[status.Get_tag()].Set('bigram', bigram)
        comm.send((None, None), dest=status.Get_source(), tag=ind)
    
    # Find number of documents in which terms appear in all documents (for TF-IDF)
    "Finding term frequency ..."
    termbow = termall(abstracts, 'bow')
    termbigram = termall(abstracts, 'bigram')
    numabs = float(len(abstracts))

    # TF-IDF
    "Creating TF-IDF ..."
    ind = 0
    for abstract in abstracts:
        # send first abstract to each slave
        if ind < size-1:
            comm.send((abstract, termbow, termbigram, numabs), dest=ind+1, tag=ind)
            ind += 1
        # continue sending rows to slaves
        else:
            tfidfbow, tfidfbigram = comm.recv(source=MPI.ANY_SOURCE, tag=MPI.ANY_TAG, status=status)
            abstracts[status.Get_tag()].Set('tfidfbow', tfidfbow)
            abstracts[status.Get_tag()].Set('tfidfbigram', tfidfbigram)
            comm.send((abstract, termbow, termbigram, numabs), dest=status.Get_source(), tag=ind)
            ind += 1
        
    # tell slaves when there are no abstracts left
    for rank in range(1,size):
        tfidfbow, tfidfbigram = comm.recv(source=MPI.ANY_SOURCE, tag=MPI.ANY_TAG, status=status)
        abstracts[status.Get_tag()].Set('tfidfbow', tfidfbow)
        abstracts[status.Get_tag()].Set('tfidfbigram', tfidfbigram)
        comm.send((None, None, None, None), dest=status.Get_source(), tag=ind)
    
    print "Done!"        
    return abstracts, dictionary

# Slave for MPI
def slave(comm):
    status = MPI.Status()
    
    # Load abstracts
    while True:
        # get message
        row, stops = comm.recv(source=0, status=status)
        
        # end if done
        if not row:
            break
        
        # create Abstract object
        dictlist = []
        abs, dictlist = load_abs(row, dictlist, stops)
        
        # send abstract back to master
        comm.send((abs, dictlist), dest=0)

    # Find bag of words and bigram
    print "Slave: find bow and bigram"
    while True:
        # get message
        abstract, dictionary = comm.recv(source=0, tag=MPI.ANY_TAG, status=status)

        # end if done
        if not abstract:
            break
        
        # find bag of words
        bow = create_bagofwords(abstract, dictionary)
        # find bigram
        bigram = create_bigram(abstract, dictionary)
        
        # send bow and bigram back to master
        comm.send((bow, bigram), dest=0, tag=status.Get_tag())
    
    # TF-IDF
    print "Slave: TF-IDF"
    while True:
        # get message
        abstract, termbow, termbigram, numabs = comm.recv(source=0, tag=MPI.ANY_TAG, status=status)
        
        # end if done
        if not abstract:
            break
        
        # find TF-IDF
        tfidfbow = create_tfidf(abstract, termbow, numabs, 'bow')
        tfidfbigram = create_tfidf(abstract, termbigram, numabs, 'bigram')
        
        # send bow and bigram back to master
        comm.send((tfidfbow, tfidfbigram), dest=0, tag=status.Get_tag())
    
    return


if __name__ == '__main__':
    # Get MPI data
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    script, filename = argv
    abstracts = []
    
    # parallel version
    if rank == 0:
        abstracts, dictionary = master(comm, filename)
    else:    
        slave(comm)
        
    #if rank == 0:
        #for abstract in abstracts:
        #    print abstract.Get('tfidfbow')
        #print len(dictionary)
        #print "parallel", abstracts[0], abstracts[0].Get('tfidfbow')
    
    # serial version
    if rank == 0:
        print "Serial version ..."

        # load stop words
        stops = set()
        stop_file = 'stopwords.txt'
        with open(stop_file, 'rU') as stopFile:
            for row in stopFile.readlines():
                stops.add(row.replace('\n', ''))

        script, filename = argv
        dictionary = []
        load(filename, abstracts, dictionary, stops)   
        for abstract in abstracts:
            # create dict of word frequency (bag of words)
            bow = create_bagofwords(abstract, dictionary)
            abstract.Set('bow', bow)
            # create dict of bigram frequency
            bigram = create_bigram(abstract, dictionary)
            abstract.Set('bigram', bigram)
        # create dict of tfidf
        serial_tfidf(abstracts, 'bow')
        serial_tfidf(abstracts, 'bigram')
        #for abstract in abstracts:
        #    print "serial", abstract, abstract.Get('tfidfbow')
        #print len(dictionary)
        #print "serial", abstracts[0], abstracts[0].Get('tfidfbow')
